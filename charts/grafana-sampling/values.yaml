metricsGeneration:
  # -- Toggle generation of spanmetrics and servicegraph metrics.
  enabled: true
  # -- Use legacy metric names that match those used by the Tempo metrics generator.
  legacy: true
  # -- Additional dimensions to add to generated metrics.
  dimensions:
    - service.namespace
    - service.version
    - deployment.environment
    - k8s.cluster.name
    - k8s.pod.name
  serviceGraph:
    # -- The interval at which metrics are flushed to downstream components.
    metricsFlushInterval: 60s
  spanMetrics:
    # -- Time period after which metrics are considered stale and are removed from the cache.
    metricsExpiration: 5m

sampling:
  # -- Toggle tail sampling.
  enabled: true
  # -- Wait time since the first span of a trace before making a sampling decision.
  decisionWait: 15s
  successfulRequests:
    # -- Toggle sampling successful requests.
    sample: true
    # -- Percentage of successful requests to sample.
    percentage: 10
  failedRequests:
    # -- Toggle sampling failed requests.
    sample: false
    # -- Percentage of failed requests to sample.
    percentage: 50
  # -- User-defined policies in alloy format.
  # @default -- A policy to sample long requests is added by default.
  extraPolicies: |-
    policy {
      name = "sample-long-requests"
      type = "and"
      and {
        and_sub_policy {
          name = "latency"
          type = "latency"
          latency {
            threshold_ms = 5000
          }
        }
        and_sub_policy {
         name = "probabilistic-policy"
         type = "probabilistic"
          probabilistic {
           sampling_percentage = 50
          }
        }
      }
    }

batch:
  # -- Configure batch processing options.
  deployment:
    timeout: 200ms
    send_batch_size: 8192
    send_batch_max_size: 0
  statefulset:
    timeout: 200ms
    send_batch_size: 8192
    send_batch_max_size: 0


deployment:
  otlp:
    # -- otlp receiver settings for deployment (loadbalancer)
    receiver:
      grpc:
        # -- gRPC max message receive size. Default to 4MB
        max_recv_msg_size: 4MB

statefulset:
  otlp:
    # -- otlp receiver settings for statefulset (sampler)
    receiver:
      grpc:
        # -- gRPC max message receive size. Default to 4MB
        max_recv_msg_size: 4MB

# @ignored Ignore alloy deployment
alloy-deployment:
  # -- Do not change this.
  nameOverride: deployment
  controller:
    type: deployment
    replicas: 1
    autoscaling:
      # -- Creates a HorizontalPodAutoscaler for controller type deployment.
      enabled: false
      # -- The lower limit for the number of replicas to which the autoscaler can scale down.
      minReplicas: 2
      # -- The upper limit for the number of replicas to which the autoscaler can scale up.
      maxReplicas: 5
      # -- Average CPU utilization across all relevant pods, a percentage of the requested value of the resource for the pods. Setting `targetCPUUtilizationPercentage` to 0 will disable CPU scaling.
      targetCPUUtilizationPercentage: 0
      # -- Average Memory utilization across all relevant pods, a percentage of the requested value of the resource for the pods. Setting `targetMemoryUtilizationPercentage` to 0 will disable Memory scaling.
      targetMemoryUtilizationPercentage: 80
  alloy:
    # This chart creates the configmaps
    configMap:
      create: false
    resources:
      requests:
        cpu: "1"
        memory: "2G"
    extraPorts:
      - name: otlp-grpc
        port: 4317
        targetPort: 4317
        protocol: TCP
      - name: otlp-http
        port: 4318
        targetPort: 4318
        protocol: TCP

# @ignored Ignore alloy statefulset
alloy-statefulset:
  # -- Do not change this.
  nameOverride: statefulset
  controller:
    type: statefulset
    replicas: 1
    autoscaling:
      # -- Creates a HorizontalPodAutoscaler for controller type deployment.
      enabled: false
      # -- The lower limit for the number of replicas to which the autoscaler can scale down.
      minReplicas: 2
      # -- The upper limit for the number of replicas to which the autoscaler can scale up.
      maxReplicas: 5
      # -- Average CPU utilization across all relevant pods, a percentage of the requested value of the resource for the pods. Setting `targetCPUUtilizationPercentage` to 0 will disable CPU scaling.
      targetCPUUtilizationPercentage: 0
      # -- Average Memory utilization across all relevant pods, a percentage of the requested value of the resource for the pods. Setting `targetMemoryUtilizationPercentage` to 0 will disable Memory scaling.
      targetMemoryUtilizationPercentage: 80
  service:
    clusterIP: None
  alloy:
    extraEnv:
      - name: GRAFANA_CLOUD_API_KEY
        value: <REQUIRED>
      - name: GRAFANA_CLOUD_PROMETHEUS_URL
        value: <REQUIRED>
      - name: GRAFANA_CLOUD_PROMETHEUS_USERNAME
        value: <REQUIRED>
      - name: GRAFANA_CLOUD_TEMPO_ENDPOINT
        value: <REQUIRED>
      - name: GRAFANA_CLOUD_TEMPO_USERNAME
        value: <REQUIRED>
      # This is required for adaptive metric deduplication in Grafana Cloud
      - name: POD_UID
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.uid
    # This chart creates the configmaps
    configMap:
      create: false
    resources:
      requests:
        cpu: "1"
        memory: "2G"
    extraPorts:
      - name: otlp-grpc
        port: 4317
        targetPort: 4317
        protocol: TCP
  # The statefulset and deployment can share the same serviceAccount and rbac roles
  serviceAccount:
    create: false
  rbac:
    create: false
liveDebugging:
  # -- Enable live debugging in the Alloy UI.
  enabled: false
